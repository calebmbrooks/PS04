---
title: "STAT/MATH 495: Problem Set 04"
author: "WRITE YOUR NAME HERE"
date: "2017-10-03"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE)
set.seed(76)
```

# Collaboration

Please indicate who you collaborated with on this assignment:


# Load packages, data, model formulas

```{r, warning=FALSE}
library(tidyverse)
credit <- read_csv("http://www-bcf.usc.edu/~gareth/ISL/Credit.csv") %>%
  select(-X1) %>%
  mutate(ID = 1:n()) %>% 
  select(ID, Balance, Income, Limit, Rating, Age, Cards, Education)
```

You will train the following 7 models on `credit_train`...

```{r}
model1_formula <- as.formula("Balance ~ 1")
model2_formula <- as.formula("Balance ~ Income")
model3_formula <- as.formula("Balance ~ Income + Limit")
model4_formula <- as.formula("Balance ~ Income + Limit + Rating")
model5_formula <- as.formula("Balance ~ Income + Limit + Rating + Age")
model6_formula <- as.formula("Balance ~ Income + Limit + Rating + Age + Cards")
model7_formula <- as.formula("Balance ~ Income + Limit + Rating + Age + Cards + Education")

```

... where `credit_train` is defined below, along with `credit_test`.

```{r}
set.seed(79)
credit_train <- credit %>% 
  sample_n(20)
credit_test <- credit %>% 
  anti_join(credit_train, by="ID")

#As linear regression
lm1 <- lm(Balance ~ 1, data = credit_train)
lm2 <- lm(Balance ~ Income, data = credit_train)
lm3 <- lm(Balance ~ Income + Limit, data = credit_train)
lm4 <- lm(Balance ~ Income + Limit + Rating, data = credit_train)
lm5 <- lm(Balance ~ Income + Limit + Rating + Age, data = credit_train)
lm6 <- lm(Balance ~ Income + Limit + Rating + Age + Cards, data = credit_train)
lm7 <- lm(Balance ~ Income + Limit + Rating + Age + Cards + Education, data = credit_train)

#getting rmse for all linear regression models in the set, with each sequential model using one more predictor than the last. Making predictions from TRAINING data
lm1rmse <- (predict(lm1, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm2rmse <- (predict(lm2, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm3rmse <- (predict(lm3, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm4rmse <- (predict(lm4, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm5rmse <- (predict(lm5, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm6rmse <- (predict(lm6, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm7rmse <- (predict(lm7, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
#concatinating rmse values into a single vector for plotting
RMSE_train <- c(lm1rmse,lm2rmse,lm3rmse,lm4rmse,lm5rmse,lm6rmse,lm7rmse)

#now predicting from TESTING data
lm1rmse <- (predict(lm1, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm2rmse <- (predict(lm2, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm3rmse <- (predict(lm3, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm4rmse <- (predict(lm4, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm5rmse <- (predict(lm5, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm6rmse <- (predict(lm6, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm7rmse <- (predict(lm7, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
#again, concatinating results
RMSE_test <- c(lm1rmse,lm2rmse,lm3rmse,lm4rmse,lm5rmse,lm6rmse,lm7rmse)
```


# RMSE vs number of coefficients

```{r, echo=TRUE, warning=FALSE, message=FALSE}



# Save results in a data frame. Note this data frame is in wide format.
results <- data_frame(
  num_coefficients = 1:7,
  RMSE_train,
  RMSE_test
) 

# Some cleaning of results
results <- results %>% 
  # More intuitive names:
  rename(
    `Training data` = RMSE_train,
    `Test data` = RMSE_test
  ) %>% 
  # Convert results data frame to "tidy" data format i.e. long format, so that we
  # can ggplot it
  gather(type, RMSE, -num_coefficients)

ggplot(results, aes(x=num_coefficients, y=RMSE, col=type)) +
  geom_line() + 
  labs(x="# of coefficients", y="RMSE", col="Data used to evaluate \nperformance of fitted model")
```


# Interpret the graph

As one might intuit, predictions from the data on which the model was trained are more accurate - the models were arrived at by optimizing (minimizing) mse relative to the training data.

Both curves show a dramatic increase in accuracy when both income and limit are used as predictors, but strangely the RMSE values begin to increase for test-data predictions from subsequent models, whereas on training data they continue to decrease. This can likely be attributed to overfitting - i.e. that as the model flexability goes up, the specificity of tailoring to the training data results in less out-of-sample predictive power.



# Bonus

Repeat the whole process, but let `credit_train` be a random sample of size 380
from `credit` instead of 20. Now compare and contrast this graph with the
one above and hypothesize as to the root cause of any differences.

```{r, echo=FALSE}
set.seed(79)
credit_train <- credit %>% 
  sample_n(380) #sample size for selecting training dataset now set to 380
credit_test <- credit %>% 
  anti_join(credit_train, by="ID")

lm1 <- lm(Balance ~ 1, data = credit_train)
lm2 <- lm(Balance ~ Income, data = credit_train)
lm3 <- lm(Balance ~ Income + Limit, data = credit_train)
lm4 <- lm(Balance ~ Income + Limit + Rating, data = credit_train)
lm5 <- lm(Balance ~ Income + Limit + Rating + Age, data = credit_train)
lm6 <- lm(Balance ~ Income + Limit + Rating + Age + Cards, data = credit_train)
lm7 <- lm(Balance ~ Income + Limit + Rating + Age + Cards + Education, data = credit_train)

#getting rmse for all linear regressions
lm1rmse <- (predict(lm1, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm2rmse <- (predict(lm2, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm3rmse <- (predict(lm3, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm4rmse <- (predict(lm4, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm5rmse <- (predict(lm5, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm6rmse <- (predict(lm6, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
lm7rmse <- (predict(lm7, credit_train)-credit_train$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_train)) %>% 
  sqrt
RMSE_train <- c(lm1rmse,lm2rmse,lm3rmse,lm4rmse,lm5rmse,lm6rmse,lm7rmse)

lm1rmse <- (predict(lm1, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm2rmse <- (predict(lm2, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm3rmse <- (predict(lm3, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm4rmse <- (predict(lm4, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm5rmse <- (predict(lm5, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm6rmse <- (predict(lm6, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
lm7rmse <- (predict(lm7, credit_test)-credit_test$Balance)^2 %>% 
  sum %>% 
  `/` (nrow(credit_test)) %>% 
  sqrt
RMSE_test <- c(lm1rmse,lm2rmse,lm3rmse,lm4rmse,lm5rmse,lm6rmse,lm7rmse)
```

```{r, echo=TRUE, warning=FALSE, message=FALSE}



# Save results in a data frame. Note this data frame is in wide format.
results <- data_frame(
  num_coefficients = 1:7,
  RMSE_train,
  RMSE_test
) 

# Some cleaning of results
results <- results %>% 
  # More intuitive names:
  rename(
    `Training data` = RMSE_train,
    `Test data` = RMSE_test
  ) %>% 
  # Convert results data frame to "tidy" data format i.e. long format, so that we
  # can ggplot it
  gather(type, RMSE, -num_coefficients)

ggplot(results, aes(x=num_coefficients, y=RMSE, col=type)) +
  geom_line() + 
  labs(x="# of coefficients", y="RMSE", col="Data used to evaluate \nperformance of fitted model")
```

In this case, the two rmse curves are much closer. This could be attributed to the models having been trained on a much larger dataset, and thus being better at predicting out-of-sample.
